{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./dataset/twitter/twitter_stock_data_merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4030 entries, 0 to 4029\n",
      "Data columns (total 11 columns):\n",
      "web-scraper-order        4030 non-null object\n",
      "web-scraper-start-url    4030 non-null object\n",
      "handle                   4029 non-null object\n",
      "name                     4029 non-null object\n",
      "content                  4029 non-null object\n",
      "replies                  2840 non-null float64\n",
      "retweets                 3430 non-null object\n",
      "favorites                3838 non-null object\n",
      "unix_timestamp           4029 non-null float64\n",
      "published_date           4028 non-null object\n",
      "url                      4029 non-null object\n",
      "dtypes: float64(2), object(9)\n",
      "memory usage: 346.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fillna with 0 into the NaN record\n",
    "df['unix_timestamp'] = df['unix_timestamp'].fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert unix_timestamp float to int type\n",
    "df['unix_timestamp'] = df['unix_timestamp'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new column call unix_time_stamp_decode and convert the unix_timestamp to GMT format\n",
    "df['unix_timestamp_decode'] = df['unix_timestamp'].apply(lambda x: time.strftime(\"%a %d %b %Y %H:%M:%S GMT\", time.gmtime(x / 1000.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new column call unix_time_stamp_decode and convert the unix_timestamp without GMT format\n",
    "df['unix_timestamp_decode_2'] = df['unix_timestamp'].apply(lambda x: pd.to_datetime(x, unit='ms'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>web-scraper-order</th>\n",
       "      <th>web-scraper-start-url</th>\n",
       "      <th>handle</th>\n",
       "      <th>name</th>\n",
       "      <th>content</th>\n",
       "      <th>replies</th>\n",
       "      <th>retweets</th>\n",
       "      <th>favorites</th>\n",
       "      <th>unix_timestamp</th>\n",
       "      <th>published_date</th>\n",
       "      <th>url</th>\n",
       "      <th>unix_timestamp_decode</th>\n",
       "      <th>unix_timestamp_decode_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1548238462-3311</td>\n",
       "      <td>https://twitter.com/search?l=&amp;q=%24AMZN%20since%3A2018-01-01%20until%3A2019-01-23&amp;src=typd&amp;lang=en</td>\n",
       "      <td>@PessimistInvest</td>\n",
       "      <td>Pessimist Investor</td>\n",
       "      <td>Wow. Lost company acquires struggling company under attack by $AMZN, $MSFT and $GOOG. Well, $IBM is probably levered enough now to short. $RHTpic.twitter.com/mrA0m6eIkr</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7</td>\n",
       "      <td>61</td>\n",
       "      <td>1540760000000</td>\n",
       "      <td>28/10/2018 13:17</td>\n",
       "      <td>/PessimistInvest/status/1056641194317570049</td>\n",
       "      <td>Sun 28 Oct 2018 20:53:20 GMT</td>\n",
       "      <td>2018-10-28 20:53:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1548238462-2761</td>\n",
       "      <td>https://twitter.com/search?l=&amp;q=%24AMZN%20since%3A2018-01-01%20until%3A2019-01-23&amp;src=typd&amp;lang=en</td>\n",
       "      <td>@DomainMondo</td>\n",
       "      <td>Domain Mondo</td>\n",
       "      <td>Attention Amazon $AMZN Investors, Day 2 May Have Just Arrived https://www.domainmondo.com/2019/01/attention-amazon-amzn-investors-day-2.html … #technology #ecommerce #stocks #StockMarket #investors #BezosDivorce #Bezos #AWS #Amazonpic.twitter.com/qTMUJEqKM0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>1547420000000</td>\n",
       "      <td>13/1/2019 15:21</td>\n",
       "      <td>/DomainMondo/status/1084591210965147648</td>\n",
       "      <td>Sun 13 Jan 2019 22:53:20 GMT</td>\n",
       "      <td>2019-01-13 22:53:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1548238462-3215</td>\n",
       "      <td>https://twitter.com/search?l=&amp;q=%24AMZN%20since%3A2018-01-01%20until%3A2019-01-23&amp;src=typd&amp;lang=en</td>\n",
       "      <td>@TMFChrisHill</td>\n",
       "      <td>Chris Hill</td>\n",
       "      <td>As a resident of northern Virginia for 25+ years, let me be very clear.\\nNo one, no one, NO ONE....is referring to Crystal City \\nas \"National Landing\".  $AMZN pic.twitter.com/8f4M6a7utq</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2</td>\n",
       "      <td>51</td>\n",
       "      <td>1542130000000</td>\n",
       "      <td>13/11/2018 9:10</td>\n",
       "      <td>/TMFChrisHill/status/1062392299932524546</td>\n",
       "      <td>Tue 13 Nov 2018 17:26:40 GMT</td>\n",
       "      <td>2018-11-13 17:26:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1548238462-2451</td>\n",
       "      <td>https://twitter.com/search?l=&amp;q=%24AMZN%20since%3A2018-01-01%20until%3A2019-01-23&amp;src=typd&amp;lang=en</td>\n",
       "      <td>@OptionsSweeper</td>\n",
       "      <td>Options Sweeper</td>\n",
       "      <td>Large $AMZN PUTS being bought up Apx 12M for 02/01 EXP 1700,1710,1720 Strikes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1548120000000</td>\n",
       "      <td>21/1/2019 17:20</td>\n",
       "      <td>/OptionsSweeper/status/1087520457136459776</td>\n",
       "      <td>Tue 22 Jan 2019 01:20:00 GMT</td>\n",
       "      <td>2019-01-22 01:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1548238462-2450</td>\n",
       "      <td>https://twitter.com/search?l=&amp;q=%24AMZN%20since%3A2018-01-01%20until%3A2019-01-23&amp;src=typd&amp;lang=en</td>\n",
       "      <td>@securixhk</td>\n",
       "      <td>SECURIX</td>\n",
       "      <td>Amazon $AMZN #Bezos Empire :pic.twitter.com/aVQypKszix</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1548090000000</td>\n",
       "      <td>21/1/2019 9:37</td>\n",
       "      <td>/securixhk/status/1087403934837293056</td>\n",
       "      <td>Mon 21 Jan 2019 17:00:00 GMT</td>\n",
       "      <td>2019-01-21 17:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  web-scraper-order  \\\n",
       "0  1548238462-3311    \n",
       "1  1548238462-2761    \n",
       "2  1548238462-3215    \n",
       "3  1548238462-2451    \n",
       "4  1548238462-2450    \n",
       "\n",
       "                                                                                web-scraper-start-url  \\\n",
       "0  https://twitter.com/search?l=&q=%24AMZN%20since%3A2018-01-01%20until%3A2019-01-23&src=typd&lang=en   \n",
       "1  https://twitter.com/search?l=&q=%24AMZN%20since%3A2018-01-01%20until%3A2019-01-23&src=typd&lang=en   \n",
       "2  https://twitter.com/search?l=&q=%24AMZN%20since%3A2018-01-01%20until%3A2019-01-23&src=typd&lang=en   \n",
       "3  https://twitter.com/search?l=&q=%24AMZN%20since%3A2018-01-01%20until%3A2019-01-23&src=typd&lang=en   \n",
       "4  https://twitter.com/search?l=&q=%24AMZN%20since%3A2018-01-01%20until%3A2019-01-23&src=typd&lang=en   \n",
       "\n",
       "             handle                name  \\\n",
       "0  @PessimistInvest  Pessimist Investor   \n",
       "1  @DomainMondo      Domain Mondo         \n",
       "2  @TMFChrisHill     Chris Hill           \n",
       "3  @OptionsSweeper   Options Sweeper      \n",
       "4  @securixhk        SECURIX              \n",
       "\n",
       "                                                                                                                                                                                                                                                             content  \\\n",
       "0  Wow. Lost company acquires struggling company under attack by $AMZN, $MSFT and $GOOG. Well, $IBM is probably levered enough now to short. $RHTpic.twitter.com/mrA0m6eIkr                                                                                            \n",
       "1  Attention Amazon $AMZN Investors, Day 2 May Have Just Arrived https://www.domainmondo.com/2019/01/attention-amazon-amzn-investors-day-2.html … #technology #ecommerce #stocks #StockMarket #investors #BezosDivorce #Bezos #AWS #Amazonpic.twitter.com/qTMUJEqKM0   \n",
       "2  As a resident of northern Virginia for 25+ years, let me be very clear.\\nNo one, no one, NO ONE....is referring to Crystal City \\nas \"National Landing\".  $AMZN pic.twitter.com/8f4M6a7utq                                                                          \n",
       "3  Large $AMZN PUTS being bought up Apx 12M for 02/01 EXP 1700,1710,1720 Strikes                                                                                                                                                                                       \n",
       "4  Amazon $AMZN #Bezos Empire :pic.twitter.com/aVQypKszix                                                                                                                                                                                                              \n",
       "\n",
       "   replies retweets favorites  unix_timestamp    published_date  \\\n",
       "0  3.0      7        61        1540760000000   28/10/2018 13:17   \n",
       "1 NaN       25       25        1547420000000   13/1/2019 15:21    \n",
       "2  8.0      2        51        1542130000000   13/11/2018 9:10    \n",
       "3 NaN       NaN      2         1548120000000   21/1/2019 17:20    \n",
       "4 NaN       1        2         1548090000000   21/1/2019 9:37     \n",
       "\n",
       "                                           url         unix_timestamp_decode  \\\n",
       "0  /PessimistInvest/status/1056641194317570049  Sun 28 Oct 2018 20:53:20 GMT   \n",
       "1  /DomainMondo/status/1084591210965147648      Sun 13 Jan 2019 22:53:20 GMT   \n",
       "2  /TMFChrisHill/status/1062392299932524546     Tue 13 Nov 2018 17:26:40 GMT   \n",
       "3  /OptionsSweeper/status/1087520457136459776   Tue 22 Jan 2019 01:20:00 GMT   \n",
       "4  /securixhk/status/1087403934837293056        Mon 21 Jan 2019 17:00:00 GMT   \n",
       "\n",
       "  unix_timestamp_decode_2  \n",
       "0 2018-10-28 20:53:20      \n",
       "1 2019-01-13 22:53:20      \n",
       "2 2018-11-13 17:26:40      \n",
       "3 2019-01-22 01:20:00      \n",
       "4 2019-01-21 17:00:00      "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort value ascending by unix_timestamp_decode_2\n",
    "df = df.sort_values(by='unix_timestamp_decode_2',ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4030 entries, 3469 to 1047\n",
      "Data columns (total 13 columns):\n",
      "web-scraper-order          4030 non-null object\n",
      "web-scraper-start-url      4030 non-null object\n",
      "handle                     4029 non-null object\n",
      "name                       4029 non-null object\n",
      "content                    4029 non-null object\n",
      "replies                    2840 non-null float64\n",
      "retweets                   3430 non-null object\n",
      "favorites                  3838 non-null object\n",
      "unix_timestamp             4030 non-null int64\n",
      "published_date             4028 non-null object\n",
      "url                        4029 non-null object\n",
      "unix_timestamp_decode      4030 non-null object\n",
      "unix_timestamp_decode_2    4030 non-null datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float64(1), int64(1), object(10)\n",
      "memory usage: 440.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the value that is NaN\n",
    "df = df.dropna(subset=['handle']) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
